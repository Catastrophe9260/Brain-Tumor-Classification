{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf30fcc-da31-488f-91f4-7866a84f05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries for the project\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, GaussianNoise, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "print(\"Number of GPUs available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816f4c3-5f1a-4571-bf82-54046a222afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'Q:/AI Projects/Datasets/Brain Tumor MRI Dataset/training'\n",
    "categories = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "\n",
    "for i in categories: # testing out how the paths for the images work in the dataset\n",
    "    path = os.path.join(data_dir, i)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9732ef9-8aa5-4395-ac8f-96853b56b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array); # just printing the last image img_array was set to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1920c17-c6a8-4c57-a213-185331031684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of an image in the dataset\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6834e4-fd81-44d0-9b91-6d0179a6d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out 4 images of each class to take a look\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "images_path = ['/glioma/Tr-glTr_0000.jpg', '/meningioma/Tr-meTr_0000.jpg', '/notumor/Tr-noTr_0000.jpg', '/pituitary/Tr-piTr_0000.jpg']\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i + 1)\n",
    "    img = cv2.imread(data_dir + images_path[i])\n",
    "    img = cv2.resize(img, (250, 250))\n",
    "    plt.imshow(img)\n",
    "    plt.title(categories[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbbd40-a3ab-40fc-99eb-bbb2ddb14e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a quick and simple model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 1), activation='relu')) # our input layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu')) # convolutional layers that perform feature extraction\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=4096, activation='relu')) # dense layers that perform classification\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GaussianNoise(0.2))\n",
    "\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GaussianNoise(0.2))\n",
    "\n",
    "model.add(Dense(units=1000, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=4, activation='softmax')) # our output layer\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b98485-7bd0-43bd-85bc-8abca0363477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling our model with the Adam optimizer\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, decay=0.0001, clipvalue=0.5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics= ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf691f-2f60-4e90-9f29-bec6f4b30bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ImageDataGenerator to prepare the images (resize, normalize, etc)\n",
    "\n",
    "generator_train = ImageDataGenerator(rescale=1./255,\n",
    "                                     featurewise_center=False,\n",
    "                                     samplewise_center=False,\n",
    "                                     featurewise_std_normalization=False,\n",
    "                                     samplewise_std_normalization=False,\n",
    "                                     zca_whitening=False,\n",
    "                                     rotation_range=0,\n",
    "                                     zoom_range = 0,\n",
    "                                     width_shift_range=0,\n",
    "                                     height_shift_range=0,\n",
    "                                     horizontal_flip=True,\n",
    "                                     vertical_flip=False) \n",
    "\n",
    "generator_test = ImageDataGenerator(rescale=1./255,\n",
    "                                    featurewise_center=False,\n",
    "                                    samplewise_center=False,\n",
    "                                    featurewise_std_normalization=False,\n",
    "                                    samplewise_std_normalization=False,\n",
    "                                    zca_whitening=False,\n",
    "                                    rotation_range=0,\n",
    "                                    zoom_range = 0,\n",
    "                                    width_shift_range=0,\n",
    "                                    height_shift_range=0,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=False)\n",
    "\n",
    "# creating the train and test data\n",
    "\n",
    "train = generator_train.flow_from_directory('Q:/AI Projects/Datasets/Brain Tumor MRI Dataset/training', target_size=(256, 256), batch_size=32, class_mode=\"categorical\", color_mode='grayscale')\n",
    "test = generator_test.flow_from_directory('Q:/AI Projects/Datasets/Brain Tumor MRI Dataset/testing', target_size=(256, 256), batch_size=32, class_mode=\"categorical\", color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed10b5-9b0a-4de4-af78-956ed3c6dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating callbacks for the model - if the model dosen't continue to improve (downward trend in loss not present) then training will stop\n",
    "\n",
    "# stop training if loss doesn't keep decreasing\n",
    "model_es = EarlyStopping(monitor = 'loss', min_delta = 1e-11, patience = 12, verbose = 1)\n",
    "model_rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 6, verbose = 1)\n",
    "\n",
    "# automatically saves the best weights of the model - based on best val_accuracy\n",
    "model_mcp = ModelCheckpoint(filepath = 'model_weights.h5', monitor = 'val_categorical_accuracy', save_best_only = True, verbose = 1)\n",
    "\n",
    "# fitting the model to our data flowing from the data generator\n",
    "history1 = model.fit(train, steps_per_epoch=5712//32, epochs=2, validation_data=test, validation_steps= 1311//32, callbacks=[model_es, model_rlr, model_mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e316a6-01f1-4d13-af53-7f8507e2d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history1.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb7f56-348f-4f8f-9e5d-9e5dda475e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting model accuracy vs. epochs\n",
    "\n",
    "plt.plot(history1.history['categorical_accuracy'])\n",
    "plt.plot(history1.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad18cb-9665-4ba4-90f3-70533e111e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting model loss vs. epochs\n",
    "\n",
    "plt.plot(history1.history['loss'])\n",
    "plt.plot(history1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2cbafc4c5c11d916f7fd6ce176ed950a53a2ff1da6a5aa6b06fc2d178a2c5e1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
